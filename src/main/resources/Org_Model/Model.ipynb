{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea39d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flask-cors in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (5.0.1)\n",
      "Requirement already satisfied: flask>=0.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask-cors) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask-cors) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask>=0.9->flask-cors) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask>=0.9->flask-cors) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from flask>=0.9->flask-cors) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from Werkzeug>=0.7->flask-cors) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask>=0.9->flask-cors) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568065cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03902dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅ Model loaded successfully\n",
      "INFO:__main__:✅ Model loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.43.5:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [21/May/2025 06:35:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pipeline = None\n",
    "le_med = LabelEncoder()\n",
    "le_diet = LabelEncoder()\n",
    "\n",
    "def train_and_save_model():\n",
    "    \"\"\"Train and save the ML pipeline and label encoders\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    \n",
    "    try:\n",
    "\n",
    "        df = pd.read_csv(\"clean_symptom_data.csv\", skiprows=1)\n",
    "        df.columns = ['Symptoms', 'Recommended Medicine', 'Diet Recommendation']\n",
    "        df = df.applymap(lambda x: str(x).strip(' \"'))\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df['Symptoms']\n",
    "        y_medicine = le_med.fit_transform(df['Recommended Medicine'])\n",
    "        y_diet = le_diet.fit_transform(df['Diet Recommendation'])\n",
    "        Y = np.vstack((y_medicine, y_diet)).T\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', MultiOutputClassifier(\n",
    "                RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        app.logger.info(\"Model training completed\")\n",
    "\n",
    "        dump(pipeline, 'medicine_pipeline.joblib')\n",
    "        dump(le_med, 'label_encoder_med.joblib')\n",
    "        dump(le_diet, 'label_encoder_diet.joblib')\n",
    "        app.logger.info(\"Model artifacts saved\")\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model training failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load trained model artifacts\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    try:\n",
    "        pipeline = load('medicine_pipeline.joblib')\n",
    "        le_med = load('label_encoder_med.joblib')\n",
    "        le_diet = load('label_encoder_diet.joblib')\n",
    "        app.logger.info(\"Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model loading failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize or train the model\"\"\"\n",
    "    try:\n",
    "        load_model()\n",
    "    except Exception as e:\n",
    "        app.logger.warning(\"Training new model...\")\n",
    "        train_and_save_model()\n",
    "        load_model()\n",
    "\n",
    "with app.app_context():\n",
    "    initialize_model()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Handle prediction requests\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'symptoms' not in data:\n",
    "            return jsonify({'error': 'Invalid request format'}), 400\n",
    "            \n",
    "        symptoms_list = data['symptoms']\n",
    "        \n",
    "        if not symptoms_list or not isinstance(symptoms_list, list):\n",
    "            return jsonify({'error': 'Symptoms must be a non-empty list'}), 400\n",
    "            \n",
    "        symptoms_text = \", \".join(symptoms_list).lower()\n",
    "        \n",
    "        if not pipeline or not hasattr(pipeline, 'predict'):\n",
    "            return jsonify({'error': 'Model not initialized'}), 500\n",
    "   \n",
    "        pred = pipeline.predict([symptoms_text])[0]\n",
    "        medicine = le_med.inverse_transform([pred[0]])[0]\n",
    "        diet = le_diet.inverse_transform([pred[1]])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'medicine': medicine,\n",
    "            'diet': diet\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Prediction error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            'error': 'Prediction failed',\n",
    "            'message': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_loaded': pipeline is not None\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with app.app_context():\n",
    "        initialize_model()\n",
    "        \n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434387d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅ Model loaded successfully\n",
      "INFO:__main__:✅ Model loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.43.5:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [21/May/2025 06:39:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pipeline = None\n",
    "le_med = LabelEncoder()\n",
    "le_diet = LabelEncoder()\n",
    "\n",
    "def train_and_save_model():\n",
    "    \"\"\"Train and save the ML pipeline and label encoders\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\"clean_symptom_data.csv\", skiprows=1)\n",
    "        df.columns = ['Symptoms', 'Recommended Medicine', 'Diet Recommendation']\n",
    "        df = df.applymap(lambda x: str(x).strip(' \"'))\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df['Symptoms']\n",
    "        y_medicine = le_med.fit_transform(df['Recommended Medicine'])\n",
    "        y_diet = le_diet.fit_transform(df['Diet Recommendation'])\n",
    "        Y = np.vstack((y_medicine, y_diet)).T\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', MultiOutputClassifier(\n",
    "                GradientBoostingClassifier(n_estimators=100, random_state=42)  # CHANGED MODEL\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        app.logger.info(\"Model training completed\")\n",
    "\n",
    "        dump(pipeline, 'medicine_pipeline.joblib')\n",
    "        dump(le_med, 'label_encoder_med.joblib')\n",
    "        dump(le_diet, 'label_encoder_diet.joblib')\n",
    "        app.logger.info(\"Model artifacts saved\")\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model training failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load trained model artifacts\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    try:\n",
    "        pipeline = load('medicine_pipeline.joblib')\n",
    "        le_med = load('label_encoder_med.joblib')\n",
    "        le_diet = load('label_encoder_diet.joblib')\n",
    "        app.logger.info(\"Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model loading failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize or train the model\"\"\"\n",
    "    try:\n",
    "        load_model()\n",
    "    except Exception as e:\n",
    "        app.logger.warning(\"Training new model...\")\n",
    "        train_and_save_model()\n",
    "        load_model()\n",
    "\n",
    "with app.app_context():\n",
    "    initialize_model()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Handle prediction requests\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'symptoms' not in data:\n",
    "            return jsonify({'error': 'Invalid request format'}), 400\n",
    "            \n",
    "        symptoms_list = data['symptoms']\n",
    "        \n",
    "        if not symptoms_list or not isinstance(symptoms_list, list):\n",
    "            return jsonify({'error': 'Symptoms must be a non-empty list'}), 400\n",
    "            \n",
    "        symptoms_text = \", \".join(symptoms_list).lower()\n",
    "        \n",
    "        if not pipeline or not hasattr(pipeline, 'predict'):\n",
    "            return jsonify({'error': 'Model not initialized'}), 500\n",
    "   \n",
    "        pred = pipeline.predict([symptoms_text])[0]\n",
    "        medicine = le_med.inverse_transform([pred[0]])[0]\n",
    "        diet = le_diet.inverse_transform([pred[1]])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'medicine': medicine,\n",
    "            'diet': diet\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Prediction error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            'error': 'Prediction failed',\n",
    "            'message': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_loaded': pipeline is not None\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with app.app_context():\n",
    "        initialize_model()\n",
    "        \n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fce24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Model loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.43.5:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [21/May/2025 07:05:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pipeline = None\n",
    "le_med = LabelEncoder()\n",
    "le_diet = LabelEncoder()\n",
    "\n",
    "def train_and_save_model():\n",
    "    \"\"\"Train and save the ML pipeline and label encoders\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(\"clean_symptom_data.csv\", skiprows=1)\n",
    "        df.columns = ['Symptoms', 'Recommended Medicine', 'Diet Recommendation']\n",
    "        df = df.applymap(lambda x: str(x).strip(' \"'))\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df['Symptoms']\n",
    "        y_medicine = le_med.fit_transform(df['Recommended Medicine'])\n",
    "        y_diet = le_diet.fit_transform(df['Diet Recommendation'])\n",
    "        Y = np.vstack((y_medicine, y_diet)).T\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', MultiOutputClassifier(\n",
    "                XGBClassifier(\n",
    "                    n_estimators=300,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5,\n",
    "                    subsample=0.8,\n",
    "                    eval_metric='mlogloss',\n",
    "                    use_label_encoder=False,\n",
    "                    random_state=42\n",
    "                )\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        app.logger.info(\"✅ Model training completed\")\n",
    "\n",
    "        dump(pipeline, 'medicine_pipeline.joblib')\n",
    "        dump(le_med, 'label_encoder_med.joblib')\n",
    "        dump(le_diet, 'label_encoder_diet.joblib')\n",
    "        app.logger.info(\"💾 Model artifacts saved\")\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model training failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load trained model artifacts\"\"\"\n",
    "    global pipeline, le_med, le_diet\n",
    "    try:\n",
    "        pipeline = load('medicine_pipeline.joblib')\n",
    "        le_med = load('label_encoder_med.joblib')\n",
    "        le_diet = load('label_encoder_diet.joblib')\n",
    "        app.logger.info(\"Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Model loading failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize or train the model\"\"\"\n",
    "    try:\n",
    "        load_model()\n",
    "    except Exception as e:\n",
    "        app.logger.warning(\"Training new model...\")\n",
    "        train_and_save_model()\n",
    "        load_model()\n",
    "\n",
    "with app.app_context():\n",
    "    initialize_model()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Handle prediction requests\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'symptoms' not in data:\n",
    "            return jsonify({'error': 'Invalid request format'}), 400\n",
    "            \n",
    "        symptoms_list = data['symptoms']\n",
    "        \n",
    "        if not symptoms_list or not isinstance(symptoms_list, list):\n",
    "            return jsonify({'error': 'Symptoms must be a non-empty list'}), 400\n",
    "            \n",
    "        symptoms_text = \", \".join(symptoms_list).lower()\n",
    "        \n",
    "        if not pipeline or not hasattr(pipeline, 'predict'):\n",
    "            return jsonify({'error': 'Model not initialized'}), 500\n",
    "   \n",
    "        pred = pipeline.predict([symptoms_text])[0]\n",
    "        medicine = le_med.inverse_transform([pred[0]])[0]\n",
    "        diet = le_diet.inverse_transform([pred[1]])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'medicine': medicine,\n",
    "            'diet': diet\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Prediction error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            'error': 'Prediction failed',\n",
    "            'message': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_loaded': pipeline is not None\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with app.app_context():\n",
    "        initialize_model()\n",
    "        \n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
